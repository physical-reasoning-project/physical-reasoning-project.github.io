<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ContPhy: Continuum Physical Concept Learning and Reasoning from Videos">
  <meta name="keywords" content="Neuro-symbolic Visual Reasoning, Physical Reasoning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>[Authors Response] ContPhy: Continuum Physical Concept Learning and Reasoning from Videos</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/prism.css" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script defer src="./static/js/prism.js"></script>
  <!-- <script src="./static/js/chart.js"></script> -->
  <script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
  <!-- <script src="https://cdn.plot.ly/plotly-latest.min.js"></script> -->
  <!-- <script type="text/javascript">
    google.charts.load('current', {'packages':['corechart']});
    google.charts.setOnLoadCallback(drawChart);

    function drawChart() {
        // Create the data table for the pie chart.
        var data = google.visualization.arrayToDataTable([
            ['Task', 'Hours per Day'],
            ['Work', 11],
            ['Eat', 2],
            ['Commute', 2],
            ['Watch TV', 2],
            ['Sleep', 7]
        ]);

        // Set chart options
        var options = {'title':'My Daily Activities',
                       'width':700,
                       'height':700};

        // Instantiate and draw the chart.
        var chart = new google.visualization.PieChart(document.getElementById('piechart'));
        chart.draw(data, options);
    }
  </script> -->
  <style>
    /* Table styles */
    table {
        width: 100%; /* Full width */
        border-collapse: collapse; /* Collapse borders */
        margin: 20px 20px; /* Add some margin around the table */
        font-size: 0.75em; /* Adjust font size */
        font-family: sans-serif; /* Use a nice font family */
        min-width: 400px; /* Minimum width */
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.15); /* Shadow for a bit of depth */
    }
    th, td {
        width: auto;
        padding: 8px 10px; /* Padding for table cells */
        text-align:center; /* Align text to the left */
    }
    thead tr {
        background-color: #009879; /* Dark green background for the header */
        color: #ffffff; /* White text color */
        text-align: left; /* Align header text to left */
        font-weight: bold; /* Make the header text bold */
    }
    tbody tr:nth-of-type(even) {
        background-color: rgb(255, 246, 249); /* Light grey background for even rows */
    }
    tbody tr:last-of-type {
        border-bottom: 2px solid #f7656c; /* Dark green border for the last row */
    }
    tbody tr:hover {
        background-color: #f0f0f0; /* Light grey background on row hover */
    }
</style>


</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div id="content0">
            <br/>
            <br/>
            <br/>
            <h1 class="title is-1 publication-title">[Authors Response] </h1><h1 class="title is-2 has-text-centered"> ContPhy: Continuum Physical Concept Learning and Reasoning from Videos</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Anonymous authors
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<nav id="navbar">
  <a href="#content0"><span style="font-weight:bolder; color: rgb(255, 106, 131);">Authors Response</span></a>
  <!-- <a href="#content5">Abstract</a>
  <a href="#content6">Motivation</a>
  <a href="#content1">Fluid</a>
  <a href="#content2">Rope</a>
  <a href="#content3">Cloth</a>
  <a href="#content4">Ball</a> -->
  <a href="#content7">Question Statistics</a>
  <a href="#content8">MLLM Prompting</a>
  <a href="#content10">More Baselines</a>
  <a href="#content9">Details</a>
</nav>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-left">
        
        <div class="column is-full-widescreen">
          <!-- Intro. -->
              <h2 class="title is-4"><span style="color: rgb(192, 101, 116);">Thanks for reviewers' time and kind advice! </span></h2> 
              <h2 class="title is-3">Menu</h2> 
              <h4 class="title is-5"><span style="color: rgb(192, 101, 116);"></span><a href="#content7">Templated and LLM-Paraphrased Question Statistics</a></h4> 
              <h4 class="title is-5"><span style="color: rgb(192, 101, 116);"></span><a href="#content8">Experiments of Various Prompting Methods on MLLMs</a></h4> 
              <h4 class="title is-5"><span style="color: rgb(192, 101, 116);"></span><a href="#content10">Experiments of More Baselines</a></h4> 
              <h4 class="title is-5"><span style="color: rgb(192, 101, 116);"></span><a href="#content9">Experiment Details</a></h4> 
          <!-- <div class="exampletoggle">
              <div id="show1" onmouseover="showexample(1)" class="active">Example 1</div>
              <div id="show2" onmouseover="showexample(2)">Example 2</div>
              <div id="show3" onmouseover="showexample(3)">Example 3</div>
          </div> -->
        </div>
      </div>
        <!-- <div class="gif-grid">
          <img src="C:/Users/87242/Downloads/output_Full (9).gif" alt="GIF 1" class="gif" data-id="1">
          <img src="C:/Users/87242/Downloads/p1 (2).gif" alt="GIF 2" class="gif" data-id="2">
          <img src="C:/Users/87242/Downloads/output_Full (6).gif" alt="GIF 3" class="gif" data-id="3">
          <img src="C:/Users/87242/Downloads/output_Full (8).gif" alt="GIF 4" class="gif" data-id="4">
        </div> -->

      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2> -->
    </div>
  </div>
</section>


<!-- <section class="section">
  <div class="container is-full-widescreen">
 
        
  </div>
</section> -->


<!-- <canvas id="myPieChart" width="400" height="400"></canvas> -->
<!-- <div id="piechart"></div>
<div id="curvePlot" style="width:100%;max-width:900px;height:500px;"></div>
<script>
  // Sample data: replace with your actual data
  var x = [1, 2, 3, 4, 5]; // X-axis data
  var y1 = [1, 2, 4, 8, 16]; // Data for the first curve
  var y2 = [1, 3, 6, 10, 15]; // Data for the second curve
  var y3 = [2, 4, 6, 8, 10]; // Data for the third curve
  var y4 = [5, 4, 3, 2, 1]; // Data for the fourth curve

  // Create traces for each set of (x, y) pairs
  var trace1 = {
      x: x,
      y: y1,
      mode: 'lines+markers',
      name: 'Curve 1'
  };

  var trace2 = {
      x: x,
      y: y2,
      mode: 'lines+markers',
      name: 'Curve 2'
  };

  var trace3 = {
      x: x,
      y: y3,
      mode: 'lines+markers',
      name: 'Curve 3'
  };

  var trace4 = {
      x: x,
      y: y4,
      mode: 'lines+markers',
      name: 'Curve 4'
  };

  var data = [trace1, trace2, trace3, trace4];

  var layout = {
      title: 'Interactive Curves',
      xaxis: {
          title: 'X-axis Label'
      },
      yaxis: {
          title: 'Y-axis Label'
      }
  };

  Plotly.newPlot('curvePlot', data, layout);
</script> -->



<section class="section">
  <div class="container is-max-widescreen">
    <!--/ Abstract. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-12"> -->
        <div id="content7">
          <br/>
          <br/>
          <br/>
          <h2 class="title is-3">Question Statistics</h2>
          <!-- <p> (Response to Reviewer aBrg, 7fPw)</p> -->
          <p>
            (In response to Reviewer <strong>aBrg</strong> and <strong>7fPw</strong>) Based on reviewer's advice, we have reported the statistics of the current question version 
            and its LLM-paraphrased version. Besides recommended <strong>lexical diversity</strong> metrics such as TTR and 
            word distribution, we also reported <strong>syntactic diversity</strong> (sentences length mean and variance), 
            <strong>question type diversity</strong> (question type number), and <strong>readability scores</strong> (Flesch-Kincaid Grade Level) 
            for reference. Statistics can be checked in the following table and figures. 
            </p>
            <br>
            <p> We also compare the diversity of our generated questions with previous works, <strong>ComPhy (ICLR 2022)</strong> and 
            <strong>CLEVRER (ICLR 2020)</strong>. Based on the metrics of TTR, our dataset appears much more 
            diverse than previous related works.
          </p>  <br>
          <p>  Considering reviewer's advice on <strong>paraphrasing questions</strong> for diversity, 
            we have employed Gemini-Pro to reword the questions. We instruct the LLM to reword the given questions 
              as diverse as possible, meanwhile keeping the original meaning strictly unchanged and the content 
              readable for common people. We provide some generated examples in the rebuttal comments. 
              The rephrasing prompts can be checked in the Details section.
          </p>
          <br>
  <table><tr><th>Question Generation Method</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>ComPhy (ICLR 2022)</th><th>CLEVRER (ICLR 2020)</th></tr><tr><th>Scenario</th><td>Fluid</td><td>Fluid</td><td>Rope</td><td>Rope</td><td>Cloth</td><td>Cloth</td><td>Ball</td><td>Ball</td><td>-</td><td>-</td></tr><tr><th>Lexical Diversity: TTR</th><td>0.0096</td><td>0.052</td><td>0.0096</td><td>0.053</td><td>0.0089</td><td>0.068</td><td>0.0066</td><td>0.049</td><td>0.0005</td><td>0.00008</td></tr><tr><th>Lexical Diversity: Word Distribution</th><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td></tr><tr><th>QA Diversity: Question Types</th><td>7 Types, See Figure</td><td>7 Types, See Figure</td><td>8 Types, See Figure</td><td>8 Types, See Figure</td><td>6 Types, See Figure</td><td>6 Types, See Figure</td><td>5 Types, See Figure</td><td>5 Types, See Figure</td><td>14 Types, See Figure</td><td>8 Types, See Figure</td></tr><tr><th>Syntactic Diversity: Sentence Length Average / Variance</th><td>13.1/3.9</td><td>13.6/10.7</td><td>13.0/6.9</td><td>13.0/11.3</td><td>12.2/8.5</td><td>11.7/11.4</td><td>15.2/10.2</td><td>15.6/19.2</td><td>12.0/8.7</td><td>12.2/12.6</td></tr><tr><th>Readability Scores: Flesch-Kincaid Grade Level</th><td>4.4</td><td>4.5</td><td>3.1</td><td>3.1</td><td>4.1</td><td>3.9</td><td>4.0</td><td>4.1</td><td>4.0</td><td>5.3</td></tr></table>
          <!-- <table><tr><th>Question Generation Method</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th></tr><tr><th>Scenario</th><td>Fluid</td><td>Fluid</td><td>Rope</td><td>Rope</td><td>Cloth</td><td>Cloth</td><td>Ball</td><td>Ball</td></tr><tr><th>Lexical Diversity: TTR</th><td>0.0096</td><td>0.052</td><td>0.0096</td><td>0.053</td><td>0.0089</td><td>0.068</td><td>0.0066</td><td>0.049</td></tr><tr><th>Lexical Diversity: Word Distribution</th><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td></tr><tr><th>QA Diversity: Question Types</th><td>7 Types, See figure</td><td>7 Types, See figure</td><td>8 Types, See figure</td><td>8 Types, See figure</td><td>6 Types, See figure</td><td>6 Types, See figure</td><td>5 Types, See figure</td><td>5 Types, See figure</td></tr><tr><th>Syntactic Diversity: Sentence Length Average / Variance</th><td>13.1/3.9</td><td>13.6/10.7</td><td>13.0/6.9</td><td>13.0/11.3</td><td>12.2/8.5</td><td>11.7/11.4</td><td>15.2/10.2</td><td>15.6/19.2</td></tr><tr><th>Readability Scores: Flesch-Kincaid Grade Level</th><td>4.4</td><td>4.5</td><td>3.1</td><td>3.1</td><td>4.1</td><td>3.9</td><td>4.0</td><td>4.1</td></tr></table> -->
          <!-- <table><tr><th>Question Generation Method</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Template-Based</th><th>LLM-Paraphrased</th><th>Typical Values in Natural Language Corpus</th></tr><tr><th>Scenario</th><td>Fluid</td><td>Fluid</td><td>Rope</td><td>Rope</td><td>Cloth</td><td>Cloth</td><td>Ball</td><td>Ball</td><td></td></tr><tr><th>Lexical Diversity: TTR</th><td>0.0096</td><td>0.052</td><td>0.0096</td><td>0.053</td><td>0.0089</td><td>0.068</td><td>0.0066</td><td>0.049</td><td>0.02 to 0.5</td></tr><tr><th>Lexical Diversity: Word Distribution</th><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td></td></tr><tr><th>QA Diversity: Question Types</th><td>7 Types, See Fugure</td><td>7 Types, See Fugure</td><td>8 Types, See Fugure</td><td>8 Types, See Fugure</td><td>6 Types, See Fugure</td><td>6 Types, See Fugure</td><td>5 Types, See Fugure</td><td>5 Types, See Fugure</td><td></td></tr><tr><th>Syntactic Diversity: Sentence Length Average / Variance</th><td>13.1/3.9</td><td>13.6/10.7</td><td>13.0/6.9</td><td>13.0/11.3</td><td>12.2/8.5</td><td>11.7/11.4</td><td>15.2/10.2</td><td>15.6/19.2</td><td>Average: 15 to 20</td></tr><tr><th>Readability Scores: Flesch-Kincaid Grade Level</th><td>4.4</td><td>4.5</td><td>3.1</td><td>3.1</td><td>4.1</td><td>3.9</td><td>4.0</td><td>4.1</td><td>3.0 to 5.0 is considered easily understandable by the average 3th to 5th grader. </td></tr></table> -->
          <!-- <table><tr><td>/</td><td>Template-Based</td><td>Template-Based</td><td>Template-Based</td><td>Template-Based</td><td>LLM Paraphrased</td><td>LLM Paraphrased</td><td>LLM Paraphrased</td><td>LLM Paraphrased</td><td>Typical Values in Natural Language Corpus</td></tr><tr><td>Linguistic Statistics</td><td>Fluid</td><td>Rope</td><td>Cloth</td><td>Ball</td><td>Fluid</td><td>Rope</td><td>Cloth</td><td>Ball</td><td>/</td></tr><tr><td>Lexical Diversity: TTR</td><td>0.0096</td><td>0.0096</td><td>0.0089</td><td>0.0066</td><td>0.052</td><td>0.053</td><td>0.068</td><td>0.049</td><td>0.02 to 0.5</td></tr><tr><td>Lexical Diversity: Word Distr</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>See Figure</td><td>N/A</td></tr><tr><td>QA Diversity: Question Type Number</td><td>7 Types, See Fugure</td><td>8 Types, See Fugure</td><td>6 Types, See Fugure</td><td>5 Types, See Fugure</td><td>7 Types, See Fugure</td><td>8 Types, See Fugure</td><td>6 Types, See Fugure</td><td>5 Types, See Fugure</td><td>N/A</td></tr><tr><td>Syntactic Diversity: Sentence Length Average / Variance</td><td>13.1/3.9</td><td>13.0/6.9</td><td>12.2/8.5</td><td>15.2/10.2</td><td>13.6/10.7</td><td>13.0/11.3</td><td>11.7/11.4</td><td>15.6/19.2</td><td>15 to 20</td></tr><tr><td>Readability Scores: Flesch-Kincaid Grade Level</td><td>4.4</td><td>3.1</td><td>4.1</td><td>4.0</td><td>4.5</td><td>3.1</td><td>3.9</td><td>4.1</td><td>A score of 5.0 to 8.0 is considered easily understandable by the average 5th to 8th grader. </td></tr></table> -->
          <br/>
          <br/>
          <h2 class="title is-4">Question Type Distribution</h2>
          <h2 class="content">
            Question distribution statistics of fluid, rope, cloth and ball scenarios. This part shows ContPhy dataset's <strong>QA type diversity</strong>.
          </h2>
          
          <!-- <div class="columns is-vcentered"> -->
            <div class="column is-12 has-text-centered">
              <img src="static/images/pie2.png" alt="distribution" class="showcase-qa">
            </div>
            <div class="columns is-vcentered">
              <div class="column is-6 has-text-centered">
                <p><strong>Question Type Distribution of CLEVRER Dataset</strong></p>
                <img src="static/images/additional/clv_typ.png" alt="distribution" class="interpolation-chart" style="width: 50%;">
              </div>
              <div class="column is-6 has-text-centered">
                <p><strong>Question Type Distribution of ComPhy Dataset</strong></p>
                <img src="static/images/additional/com_typ.png" alt="distribution" class="interpolation-chart" style="width: 50%;">
              </div>
              
            </div>
            
          <!-- </div> -->
          <br/>
          <br/>
          <h2 class="title is-4">Word Distribution of Templated and Paraphrased Questions</h2>
          <!-- <h2 class="content">
            Row 1: From left to right, type / token ratios are <strong>57/5896, 75/7804, 49/5488, 45/6858</strong>.
            <br>
            Row 2: From left to right, type / token ratios are <strong>320/6117, 414/7810, 359/5294, 342/7027</strong>.
          </h2> -->

          <!-- <div class="column is-12 has-text-centered">
            <img src="static/images/word_distr.png" alt="distribution" class="showcase-qa" >
          </div> -->
          <p>This part shows ContPhy dataset's <strong>lexical diversity</strong> before and after LLM paraphrasing.</p>
          <br>
          <div class="columns is-vcentered">
            <div class="column is-3 has-text-centered">
              <p>Fluid Templated QA</p>
              <p>TTR=57/5896</p>
              <img src="static/images/additional/1-1.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Rope Templated QA</p>
              <p>TTR=75/7804</p>
              <img src="static/images/additional/1-2.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Cloth Templated QA</p>
              <p>TTR=49/5488</p>
              <img src="static/images/additional/1-3.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Ball Templated QA</p>
              <p>TTR=45/6858</p>
              <img src="static/images/additional/1-4.png" alt="distribution" class="interpolation-pie">
            </div>
          </div>
          <div class="columns is-vcentered">
            <div class="column is-3 has-text-centered">
              <p>Fluid LLM-Paraphrased QA</p>
              <p>TTR=320/6117</p>
              <img src="static/images/additional/2-1.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Rope LLM-Paraphrased QA</p>
              <p>TTR=414/7810</p>
              <img src="static/images/additional/2-2.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Cloth LLM-Paraphrased QA</p>
              <p>TTR=359/5294</p>
              <img src="static/images/additional/2-3.png" alt="distribution" class="interpolation-pie">
            </div>
            <div class="column is-3 has-text-centered">
              <p>Ball LLM-Paraphrased QA</p>
              <p>TTR=342/7027</p>
              <img src="static/images/additional/2-4.png" alt="distribution" class="interpolation-pie">
            </div>
          </div>
          <div class="columns is-vcentered">
            <div class="column is-6 has-text-centered">
              <p><strong>Word Distribution of CLEVRER Dataset</strong></p>
              <img src="static/images/additional/clv_wd.png" alt="distribution" class="interpolation-chart" style="width: 50%;">
            </div>
            <div class="column is-6 has-text-centered">
              <p><strong>Word Distribution of ComPhy Dataset</strong></p>
              <img src="static/images/additional/com_wd.png" alt="distribution" class="interpolation-chart" style="width: 50%;">
            </div>
            
          </div>

          
      <!-- </div> -->
      <!-- <div class="column is-four-fifths">
        <div id="content8">
          <br/>
          <br/>
          <h2 class="title is-3">Question Distribution</h2>
          <div class="columns is-vcentered">
            <div class="column is-12 has-text-centered">
              <img src="static/images/distr1.png" alt="distribution" class="showcase-qa">
            </div>
          </div>
          <h2 class="content has-text-centered">
            Question distribution statistics of fluid, rope, cloth and ball.
          </h2>
        </div>
      </div> -->
    <!-- </div> -->
    <!-- Abstract. -->
    <!-- <div class="columns is-centered has-text-centered"> -->
      <!-- <div class="column is-max-widescreen"> -->
        <div id="content8">
          <br/>
          <br/>
          <br/>
          
          <h2 class="title is-3"><span style="color: rgb(192, 101, 116);"></span>Experiments of Various Prompting Methods on MLLM</h2> 
          <p>On this table, experimental outcomes of different prompting methods are listed. During rebuttal, we experimented different prompting methods on MLLMs that may affect their performance, such as different ways of questioning, instructing, describing, and sampling the physical events in the video.</p>
          <br>
          <p><strong>Table Description</strong> | We compute the average scores in each scenario, as shown at row 1 to row 4.  We mark the row-wise highest value in <strong><span style="color:rgb(255, 0, 0)">red</strong>, the second highest value in <strong><span style="color:rgb(0, 60, 255)">blue</span></strong>, as well as some other highest values in <strong>bold</strong>. The following rows (5-26) store all experiment data for detailed investigation. </p>
          <br>
          <!-- <p><strong>Data Analysis</strong> | We observe that the Gemini-Pro-Vision(Gemini)'s performance varies with scenarios. For rope scenario, as we pack the prompt with more helpful scenario-specific instructions, the scores significantly improve, for example, prompting with designed scenario-specific guideline, in-context QA examples, or human explained examples. Accurately describing the events in the current video with full texts, assembling NEWTON's approach, also raises performance scores. However, as for the fluid, cloth, and ball scenarios, these methods act as a somehow converse role, which is seemingly weird phenomenon.   </p> -->
          
          <table><tr><th>Model: Gemini-Pro-Vision</th><th>Human Performance</th><th>Random Choice</th><th>Average of Columns on the Right</th><th>a) Question Only (Visual Input, 0-shot)</th><th>b) Question Only (Text Only)</th><th>c) Scenario-Specific Guideline</th><th>d) In-Context QA Examples</th><th>e) Human Explained Examples</th><th>f) Upsampled Video (11→16 Frames, Higher Resolution)</th><th>g) LLM-Paraphrased Questions (Visual Input, 0-shot)</th><th>h) LLM-Paraphrased Questions (Text Only)</th><th>i) NEWTON Approach (Text Only)</th></tr><tr><th>Average Rope</th><th><span style="color: red;">85.2</span> </th><td>31.1 </td><td>31.1 </td><td>31.5 </td><td>28.6 </td><th>34.1 </th><th>33.5 </th><th><span style="color: rgb(0, 61, 245);">36.2</span> </th><td>29.9 </td><td>27.9 </td><td>26.1 </td><th>32.3 </th></tr><tr><th>Average Fluid</th><th><span style="color: red;">67.9</span> </th><th>31.2 </th><td>26.1 </td><td>25.2 </td><th>31.0 </th><td>25.1 </td><td>26.4 </td><td>23.1 </td><td>23.6 </td><td>23.4 </td><th><span style="color: rgb(0, 61, 245);">32.9</span> </th><td>23.9 </td></tr><tr><th>Average Cloth</th><th><span style="color: red;">79.4</span> </th><td>48.3 </td><td>47.5 </td><td>45.0 </td><th><span style="color: rgb(0, 61, 245);">53.4</span> </th><td>46.4 </td><td>45.6 </td><td>48.8 </td><td>44.4 </td><td>43.5 </td><th>51.6 </th><td>48.9 </td></tr><tr><th>Average Ball</th><th><span style="color: red;">81.0</span> </th><td>42.9 </td><td>41.6 </td><td>43.0 </td><th>44.3 </th><td>43.8 </td><td>35.4 </td><td>32.1 </td><td>43.5 </td><td>43.4 </td><th><span style="color: rgba(0, 61, 245);">46.2</span> </th><td>43.2 </td></tr><tr><td>Rope P</td><td>84.7</td><td>30.0</td><td>35.9 </td><td>35.5</td><td>34.0</td><td>33.5</td><td>34.5</td><td>39.0</td><td>34.0</td><td>30.5</td><td>32.0</td><td>50.0</td></tr><tr><td>Rope CO</td><td>90.2</td><td>51.3</td><td>47.3 </td><td>48.2</td><td>44.4</td><td>46.6</td><td>51.2</td><td>53.4</td><td>46.6</td><td>43.8</td><td>44.0</td><td>47.8</td></tr><tr><td>Rope CQ</td><td>75.0</td><td>14.7</td><td>9.6 </td><td>12.0</td><td>5.6</td><td>14.8</td><td>13.4</td><td>12.0</td><td>11.3</td><td>9.2</td><td>5.6</td><td>2.1</td></tr><tr><td>Rope GO</td><td>91.9</td><td>55.2</td><td>52.1 </td><td>51.6</td><td>48.9</td><td>54.7</td><td>56.1</td><td>57.4</td><td>48.9</td><td>49.3</td><td>47.1</td><td>54.7</td></tr><tr><td>Rope GQ</td><td>84.0</td><td>4.5</td><td>10.7 </td><td>10.3</td><td>10.3</td><td>20.7</td><td>12.1</td><td>19.0</td><td>8.6</td><td>6.9</td><td>1.7</td><td>6.9</td></tr><tr><td>Fluid P</td><td>75.8</td><td>33.3</td><td>17.9 </td><td>10.0</td><td>28.0</td><td>22.0</td><td>24.0</td><td>21.0</td><td>19.0</td><td>11.0</td><td>22.0</td><td>4.0</td></tr><tr><td>Fluid CO</td><td>82.5</td><td>52.9</td><td>48.7 </td><td>47.3</td><td>48.0</td><td>45.7</td><td>48.3</td><td>46.0</td><td>46.3</td><td>45.0</td><td>55.3</td><td>56.0</td></tr><tr><td>Fluid CQ</td><td>60.6</td><td>6.0</td><td>4.7 </td><td>5.1</td><td>6.4</td><td>2.6</td><td>5.1</td><td>2.6</td><td>0.0</td><td>2.6</td><td>15.4</td><td>2.6</td></tr><tr><td>Fluid GO</td><td>75.0</td><td>59.9</td><td>46.0 </td><td>44.4</td><td>63.3</td><td>40.8</td><td>42.6</td><td>36.7</td><td>40.8</td><td>43.2</td><td>60.4</td><td>42.0</td></tr><tr><td>Fluid GQ</td><td>64.3</td><td>7.5</td><td>7.6 </td><td>11.3</td><td>11.3</td><td>5.7</td><td>7.5</td><td>3.8</td><td>5.7</td><td>5.7</td><td>11.3</td><td>5.7</td></tr><tr><td>Fluid PO</td><td>73.9</td><td>53.8</td><td>52.2 </td><td>52.4</td><td>51.2</td><td>53.1</td><td>51.6</td><td>48.8</td><td>49.2</td><td>52.0</td><td>54.3</td><td>57.1</td></tr><tr><td>Fluid PQ</td><td>42.9</td><td>4.8</td><td>5.5 </td><td>5.8</td><td>8.7</td><td>5.8</td><td>5.8</td><td>2.9</td><td>4.3</td><td>4.3</td><td>11.6</td><td>0.0</td></tr><tr><td>Clotd P</td><td>81.4</td><td>46.7</td><td>49.0 </td><td>42.0</td><td>54.0</td><td>46.0</td><td>54.0</td><td>54.0</td><td>47.0</td><td>39.0</td><td>48.0</td><td>57.0</td></tr><tr><td>Clotd PO</td><td>79.6</td><td>52.2</td><td>50.6 </td><td>50.1</td><td>56.1</td><td>50.1</td><td>45.9</td><td>50.3</td><td>47.7</td><td>50.1</td><td>55.7</td><td>49.2</td></tr><tr><td>Clotd PQ</td><td>77.3</td><td>46.0</td><td>42.9 </td><td>43.0</td><td>50.0</td><td>43.0</td><td>37.0</td><td>42.0</td><td>38.5</td><td>41.5</td><td>51.0</td><td>40.5</td></tr><tr><td>Ball P</td><td>76.9</td><td>53.5</td><td>53.4 </td><td>54.0</td><td>54.0</td><td>52.0</td><td>53.0</td><td>46.0</td><td>56.0</td><td>58.0</td><td>61.0</td><td>47.0</td></tr><tr><td>Ball CO</td><td>93.9</td><td>53.6</td><td>55.7 </td><td>60.9</td><td>60.1</td><td>56.4</td><td>47.3</td><td>43.2</td><td>60.5</td><td>57.2</td><td>57.6</td><td>58.4</td></tr><tr><td>Ball CQ</td><td>90.9</td><td>30.4</td><td>27.0 </td><td>29.6</td><td>37.0</td><td>28.4</td><td>13.6</td><td>7.4</td><td>34.6</td><td>27.2</td><td>28.4</td><td>37.0</td></tr><tr><td>Ball GO</td><td>89.7</td><td>55.9</td><td>55.9 </td><td>54.1</td><td>60.1</td><td>57.9</td><td>55.2</td><td>57.4</td><td>54.1</td><td>53.9</td><td>55.6</td><td>55.2</td></tr><tr><td>Ball GQ</td><td>84.6</td><td>30.2</td><td>24.2 </td><td>24.6</td><td>34.4</td><td>31.1</td><td>6.6</td><td>11.5</td><td>23.0</td><td>27.9</td><td>32.8</td><td>26.2</td></tr><tr><td>Ball PO</td><td>72.5</td><td>50.6</td><td>51.0 </td><td>51.7</td><td>47.1</td><td>52.9</td><td>51.1</td><td>43.7</td><td>50.6</td><td>52.3</td><td>56.9</td><td>52.9</td></tr><tr><td>Ball PQ</td><td>58.8</td><td>25.9</td><td>24.1 </td><td>25.9</td><td>17.2</td><td>27.6</td><td>20.7</td><td>15.5</td><td>25.9</td><td>27.6</td><td>31.0</td><td>25.9</td></tr></table>
          <!-- <table><tr><td>Model: Gemini-Pro-Vision</td><th>Human Performance</th><th>Random Choice</th><th>Average of Columns on the Right</th><td>a) Question Only</td><td>b) Question Only (Text Only)</td><td>c) Scenario-Specific Guideline</td><td>d) <br> In-Context QA Examples</td><td>e) <br>Human Explained Examples</td><td>f) <br>Upsampled Video (11→16 Frames, Higher Resolution)</td><td>g) <br> LLM-Paraphrased Questions</td><td>h) <br>LLM-Paraphrased Questions (Text Only)</td><td>i) <br>NEWTON Approach (Text Only)</td></tr><tr><td>Rope P</td><td>84.7</td><td>30.0</td><td>35.9 </td><td>35.5</td><td>34.0</td><td>33.5</td><td>34.5</td><td>39.0</td><td>34.0</td><td>30.5</td><td>32.0</td><td>50.0</td></tr><tr><td>Rope CO</td><td>90.2</td><td>51.3</td><td>47.3 </td><td>48.2</td><td>44.4</td><td>46.6</td><td>51.2</td><td>53.4</td><td>46.6</td><td>43.8</td><td>44.0</td><td>47.8</td></tr><tr><td>Rope CQ</td><td>75.0</td><td>14.7</td><td>9.6 </td><td>12.0</td><td>5.6</td><td>14.8</td><td>13.4</td><td>12.0</td><td>11.3</td><td>9.2</td><td>5.6</td><td>2.1</td></tr><tr><td>Rope GO</td><td>91.9</td><td>55.2</td><td>52.1 </td><td>51.6</td><td>48.9</td><td>54.7</td><td>56.1</td><td>57.4</td><td>48.9</td><td>49.3</td><td>47.1</td><td>54.7</td></tr><tr><td>Rope GQ</td><td>84.0</td><td>4.5</td><td>10.7 </td><td>10.3</td><td>10.3</td><td>20.7</td><td>12.1</td><td>19.0</td><td>8.6</td><td>6.9</td><td>1.7</td><td>6.9</td></tr><tr><td>Fluid P</td><td>75.8</td><td>33.3</td><td>17.9 </td><td>10.0</td><td>28.0</td><td>22.0</td><td>24.0</td><td>21.0</td><td>19.0</td><td>11.0</td><td>22.0</td><td>4.0</td></tr><tr><td>Fluid CO</td><td>82.5</td><td>52.9</td><td>48.7 </td><td>47.3</td><td>48.0</td><td>45.7</td><td>48.3</td><td>46.0</td><td>46.3</td><td>45.0</td><td>55.3</td><td>56.0</td></tr><tr><td>Fluid CQ</td><td>60.6</td><td>6.0</td><td>4.7 </td><td>5.1</td><td>6.4</td><td>2.6</td><td>5.1</td><td>2.6</td><td>0.0</td><td>2.6</td><td>15.4</td><td>2.6</td></tr><tr><td>Fluid GO</td><td>75.0</td><td>59.9</td><td>46.0 </td><td>44.4</td><td>63.3</td><td>40.8</td><td>42.6</td><td>36.7</td><td>40.8</td><td>43.2</td><td>60.4</td><td>42.0</td></tr><tr><td>Fluid GQ</td><td>64.3</td><td>7.5</td><td>7.6 </td><td>11.3</td><td>11.3</td><td>5.7</td><td>7.5</td><td>3.8</td><td>5.7</td><td>5.7</td><td>11.3</td><td>5.7</td></tr><tr><td>Fluid PO</td><td>73.9</td><td>53.8</td><td>52.2 </td><td>52.4</td><td>51.2</td><td>53.1</td><td>51.6</td><td>48.8</td><td>49.2</td><td>52.0</td><td>54.3</td><td>57.1</td></tr><tr><td>Fluid PQ</td><td>42.9</td><td>4.8</td><td>5.5 </td><td>5.8</td><td>8.7</td><td>5.8</td><td>5.8</td><td>2.9</td><td>4.3</td><td>4.3</td><td>11.6</td><td>0.0</td></tr><tr><td>Cloth P</td><td>81.4</td><td>46.7</td><td>49.0 </td><td>42.0</td><td>54.0</td><td>46.0</td><td>54.0</td><td>54.0</td><td>47.0</td><td>39.0</td><td>48.0</td><td>57.0</td></tr><tr><td>Cloth PO</td><td>79.6</td><td>52.2</td><td>50.6 </td><td>50.1</td><td>56.1</td><td>50.1</td><td>45.9</td><td>50.3</td><td>47.7</td><td>50.1</td><td>55.7</td><td>49.2</td></tr><tr><td>Cloth PQ</td><td>77.3</td><td>46.0</td><td>42.9 </td><td>43.0</td><td>50.0</td><td>43.0</td><td>37.0</td><td>42.0</td><td>38.5</td><td>41.5</td><td>51.0</td><td>40.5</td></tr><tr><td>Ball P</td><td>76.9</td><td>53.5</td><td>53.4 </td><td>54.0</td><td>54.0</td><td>52.0</td><td>53.0</td><td>46.0</td><td>56.0</td><td>58.0</td><td>61.0</td><td>47.0</td></tr><tr><td>Ball CO</td><td>93.9</td><td>53.6</td><td>55.7 </td><td>60.9</td><td>60.1</td><td>56.4</td><td>47.3</td><td>43.2</td><td>60.5</td><td>57.2</td><td>57.6</td><td>58.4</td></tr><tr><td>Ball CQ</td><td>90.9</td><td>30.4</td><td>27.0 </td><td>29.6</td><td>37.0</td><td>28.4</td><td>13.6</td><td>7.4</td><td>34.6</td><td>27.2</td><td>28.4</td><td>37.0</td></tr><tr><td>Ball GO</td><td>89.7</td><td>55.9</td><td>55.9 </td><td>54.1</td><td>60.1</td><td>57.9</td><td>55.2</td><td>57.4</td><td>54.1</td><td>53.9</td><td>55.6</td><td>55.2</td></tr><tr><td>Ball GQ</td><td>84.6</td><td>30.2</td><td>24.2 </td><td>24.6</td><td>34.4</td><td>31.1</td><td>6.6</td><td>11.5</td><td>23.0</td><td>27.9</td><td>32.8</td><td>26.2</td></tr><tr><td>Ball PO</td><td>72.5</td><td>50.6</td><td>51.0 </td><td>51.7</td><td>47.1</td><td>52.9</td><td>51.1</td><td>43.7</td><td>50.6</td><td>52.3</td><td>56.9</td><td>52.9</td></tr><tr><td>Ball PQ</td><td>58.8</td><td>25.9</td><td>24.1 </td><td>25.9</td><td>17.2</td><td>27.6</td><td>20.7</td><td>15.5</td><td>25.9</td><td>27.6</td><td>31.0</td><td>25.9</td></tr></table> -->
          <br>
          <h2 class="title is-4">Response and Data Analysis</h2>
            <!-- <br> -->
            <p>1. (For Reviewer <strong>UVKV</strong>'s suggestion) For thorough evaluation, we have added 
            a new baseline assembling <strong>NEWTON</strong>'s approach that first transforms the visual 
            input into text description of the scene objects and their dynamics and then feed the 
            description to the LLM. <strong>(Check more details in rebuttal text)</strong> 
            Following the text description of the scene, the 
            questions are added below the given information. We feed the prompt into the Gemini 
            Pro Vision. The results are shown in table. It is shown that, 
            the text description of the rope scene can benefit the MLLM's 
            understanding of the physical events happening in the video, while we do not 
            observe significant increase of performance compared with the question-only 
            blind model in other three scenarios. <strong>We guess the reason lies in that the rope 
            scenario is quite different from the other three in ways of describing the physical 
            dynamics.</strong> The rope is relatively easy to predict and reason once the model knows 
            the <strong>connection lists of ropes and the motion patterns (rotation and motion directions)</strong>. 
            The causal relations acquired from the text are relatively obvious for pretrained 
            language models. This reasoning chain does not involve too much physical dynamic 
            reasoning and prediction, thus improving the performance of it on rope scenario. 
            But as for the fluid, cloth, and ball scenarios, <strong>the question-solving process 
            greatly involves and evaluates the language model's ability to do physical dynamic 
            reasoning</strong>. Besides, due to the <strong>upper limit of tokens</strong> for Gemini API, we are only 
            able to provide a small number of particles in sparsely sampled frames, which may 
            also constrain LLMs' understanding on these temporal physical scenarios. This 
            indicates that some of nowadays language models, such as Gemini-Pro, are not 
            competent on continuum physical reasoning and dynamic inference, regardless of 
            the input modality. The discussion on the related work <strong>NEWTON</strong> 
            will be added in the later version.
          </p>
          <br>
          <p>2. (For Reviewer <strong>xL5z</strong>'s suggestion) We gathered some <strong>human explanations</strong> 
            to some <strong>carefully selected QA examples</strong> 
            (mainly designed ourselves) and test its effectiveness by adding it into the prompt 
            of multimodal large language models. The detailed prompt examples and experiment 
            results can be found at the rebuttal webpage. As shown in the table, 
            we can observe <strong>the increase of average performance in most scenarios (rope, fluid, 
            and cloth scenarios)</strong>, which might imply that prompting with in-context examples 
            can provide models with more information about the scene and also some evidence to 
            support reasoning about the events. When we add detailed human explanations, the 
            performance improves more for rope and cloth scenarios.</p>
          <br>
          <p>
            3. (For Reviewer <strong>aBrg</strong>'s concerns) We design the question templates by brainstorming. 
            About 10 people are involved in proposing, implementing, and modifying templates. More details of templates 
            are shown in Table 3-7 and Figure 5 of our paper. At this webpage, we list more linguistic statistics of the QA dataset. 
            Considering your concern about the effect of template-based questions, we also utilize <strong>LLMs to paraphrase</strong> 
            the questions for <strong>better diversity</strong>. The rewording prompt we used could be checked at this page. 
            <strong>Question statistics and MLLM's performances on template-based questions and LLM-paraphrased questions</strong> are compared 
            in the table (Rebuttal R2-1) and table (Rebuttal R2-2). We also provide <strong>statistics of previous works</strong>, ComPhy and CLEVRER.
            On templated and paraphrased datasets, The model performances are very close, indicating that templated QA may   
            not affect models' performance on understanding and answering questions of physical scenarios.
          </p>
          <br>
          <p>
            4. (For Reviewer <strong>7fPw</strong>'s concerns and suggestions) (i) The advice on <strong>paraphrasing 
            questions is quite inspirational</strong> and could contribute to the <strong>diversity</strong> of QA dataset. 
            We have utilized Gemini-Pro to reword the questions. The prompts we use can be 
            checked at this page. We instruct the LLM to reword the given 
            questions <strong>as diverse as possible and keep the original meaning strictly 
            unchanged and the content readable for common people as well</strong>. We provide 
            some generated examples in Reviewer 7fPw's rebuttal comments. As shown in Table (Rebuttal R3-1), 
            paraphrases from LLMs can increase the qualities of question-answer pairs in terms of 
            lexical diversity and word distribution while keeping the semantics of QA pairs unchanged. 
            We also compare the diversity of our generated questions with previous works, ComPhy and CLEVRER. 
            Based on the TTR metric, our dataset is much more diverse than previous works. 
            Based on the experiment results, the model has relatively close performance on templated and paraphrased datasets.
            
            (ii) For the original experiments presented in paper, 
            The experiment was in a zero-shot setting and we did not include any scenario-specific guidelines or 
            any in-context QA examples in prompt. During rebuttal, 
            we carefully considered your opinion and experimented 
            with our <strong>self-designed scenario-specific guidelines, in-context examples, 
            as well as elaborate human explanations for example questions</strong>. 
            During rebuttal stage, We tested <strong>full-size(1920x1080) images 
            and raised subsampling frame number to 16 frames</strong>, which is 
            the <strong>acceptable upper limit</strong> of Gemini-Pro-Vision's visual 
            input. Full results and prompt examples can be checked at this page.

            <strong>Packing the prompt with more scenario instructions, 
            few-shot QA examples, and even detailed human explanations 
            could benefit MLLM's understanding of the physical scene in 
            various ways.</strong> But we do not discovered any benefit of 
            upsampling the videos, probably because the MLLM (Gemini)'s 
            visual understanding ability <strong>suffers from the upper limit of its visual API</strong>.
          </p>
          <br>
          <h2 class="title is-4">Comparison with Human Performance</h2>
          <p>From method <strong>a) to i) (check table headers)</strong>, we draw the average, maximum, and minimum values of various prompting method scores on this radar chart. For reference, human performance on each question type is plotted as well. For normalization of visual effects, values on chart are processed by subtracting the random choice scores.</p>
          <br>
<!-- of visual effects <div class="column is-8 has-text-centered"> -->
            <img src="static/images/mllm_performance2.png" alt="distribution" class="showcase-qa" style="width: 70%; display: block; margin: auto;">
          <!-- </div> -->
          <br>
         


          <br>


          <!-- <h2 class="content has-text-justified">
            (For convenience of reference) This is the comparison between baselines and human on ContPhy evaluation. We list a small number of selected values among the results from various question families, <strong>Prop</strong>erty, <strong>Counter</strong>factual,
            <strong>Goal</strong>-driven and <strong>Pred</strong>ictive questions. Accuracies are reported with per <strong>opt</strong>ion and per <strong>ques</strong>tion.
          </h2>
          <div class="columns is-centered is-vcentered">
            <div class="column is-8 has-text-centered">
              <img src="static/images/experiment.png" alt="experiments" class="showcase-qa" style="width: 80%; display: block; margin: auto;">
            </div>
          </div> -->
          
        </div>

        <div id="content10">
          <br>
          <br>
          <br>
          <h2 class="title is-3"><span style="color: rgb(192, 101, 116);"></span>Experiments of More Baselines</h2> 
          <!-- <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Prompt to paraphrase questions</h2>  -->
          <!-- code here -->
          <!-- <br> -->
          <p>1. (In response to Reviewer <strong>UVKV</strong>) During this rebuttal, we have implemented <strong>PIP</strong> 
            and <strong>PhyDNet</strong> for the proposed ContPhy dataset. Based on the original 
            implementation released by the authors, we first generated object 
            masks based on each question and fed them into models, together with 
            the video features. For the open-ended questions, we added a fully-connecter 
            layer to predict the answer labels with a cross-entropy loss. Results are shown 
            in table. PIP and PhyDNet achieve competitive overall performance and excel 
            in some settings (e.g. counterfactual questions in fluid setting) than previous 
            best performance from vision models. However, these specialized models also 
            have limitations in some scenarios like Rope and Cloth. We hypothesize 
            the reasons are that these models are mainly designed for physical 
            reasoning tasks with simple visual primitives, like sphere collision 
            and movement. However, our dataset focuses on continuum objects in diverse 
            environments and different question types, which makes it difficult for 
            these models to grasp the physical rules behind the scenarios. We will add 
            the new baselines into the later version of the paper.</p>
          <br>
          <p>
            2. (In response to Reviewer <strong>7fPw</strong>) We added a new transformer-based video-QA baseline, <strong>Violet</strong>, which takes 
            videos as input, can be directly fine-tuned on our dataset. We showed the performance 
            of Violet in the table and compared it with other fine-tuned vision baselines and 
            zero-shot video baselines (MLLMs). The results of Violet are fine-tuned based on 
            the pre-trained checkpoint on YT180, WebVid2.5M and CC3M. Based on the results shown in table, 
            we can find that the fine-tuned Violet exhibits excellent overall performance. Violet achieves competitive results with the 
            best performance of all previous vision models in some settings (such as Rope CO and
             Fluid GO), and even surpasses the best in Fluid CO and Ball CQ. Compared with zero-shot 
             video-language models, which are GPT-4V and Gemini, Violet excels in most of the 
             settings, showing the advantages of fine-tuning large pre-trained models on ContPhy's 
             videos. However, the performance of Violet is far away from human performance, showing 
             the challenges of our ContPhy datasets. <strong>Due to the contraint time slots of the rebuttal period, 
             we have not setup the evaluation pipeline for Vl-adapter, since the environment dependency of 
             the feature extraction stage of VL-Adapter is quite complex. We will add this baseline in the later 
             version.</strong>
          </p>
          <br>
          <p>
            3. (In response to Reviewer <strong>aBrg</strong>) As suggested by the reviewer, we experiment with 
            <strong>point cloud</strong> and add these features to CNN-LSTM and MAC baselines. We first utilize 
            <strong>ULIP-2[A]</strong> pre-trained models with <strong>PointBert[B]</strong> backbones to extract features for 
            all object point clouds in the scenarios. These features are concatenated together 
            with the vision input, and are fed into vision baselines. Results are shown in table.
           With the help of point clouds, vision models are exposed to large improvements in 
           almost all settings. We articulate that point cloud features can improve vision 
           model performance since it provides additional information like object locations 
           and spatial relationship, which is important to predict objects' dynamics. We 
           will add such analysis into the later version.
          </p>
          <br>
          <p><strong>Table Description</strong> | From row 1 to 4, We mark the row-wise highest value in <strong><span style="color:rgb(255, 0, 0)">red</strong>, the second highest value in <strong><span style="color:rgb(0, 60, 255)">blue</span></strong>, as well as some other highest values in <strong>bold</strong>. The following rows (5-26) store all experiment data for detailed investigation. </p>
          <br>
          <table><tr><th></th><th>Gemini</th><th>GPT-4v</th><th>Previous Vision Best</th><th>PIP</th><th>PhyDNet</th><th>Violet</th><th>CNN-LSTM</th><th>CNN-LSTM+PC</th><th>MAC</th><th>MAC+PC </th></tr><tr><th>Rope Avg.</th><td>31.5</td><td>34.1</td><th><span style="color: red;">50.1</span></th><td>41.6</td><th><span style="color: rgb(0, 61, 245);">48.9</span></th><td>45.4</td><td>45.9</td><th>48</th><td>44.9</td><th>47.3</th></tr><tr><th>Fluid Avg.</th><td>25.2</td><td>29.7</td><th><span style="color: red;">42.1</span></th><td>35.8</td><th>39.1</th><th><span style="color: rgb(0, 61, 245);">39.8</span></th><td>37.3</td><th>38.5</th><td>32.6</td><th>37.8 </th></tr><tr><th>Cloth Avg.</th><td>45</td><td>49.8</td><th><span style="color: red">61.8</span></th><td>54</td><td>56.5</td><th><span style="color: rgb(0, 61, 245);">59.6</span></th><td>57.2</td><th>59.1</th><td>56</td><th>57.8</th></tr><tr><th>Ball Avg.</th><td>43</td><td>41.5</td><th><span style="color: rgb(0, 61, 245);">53.4</span></th><td>41.2</td><td>46.7</td><td>42.9</td><td>49.7</td><th><span style="color:red">55.9</span></th><td>43.6</td><th>52.1</th></tr><tr><td>Rope P</td><td>35.5</td><td>48</td><td>60.7</td><td>31.5</td><td>59</td><td>51.7</td><td>52.7</td><td>55</td><td>53.3</td><td>57.7 </td></tr><tr><td>Rope CO</td><td>48.2</td><td>42</td><td>76.2</td><td>75.2</td><td>77.7</td><td>76</td><td>74</td><td>75.4</td><td>74.2</td><td>76 </td></tr><tr><td>Rope CQ</td><td>12</td><td>11.3</td><td>50.7</td><td>48.3</td><td>47.9</td><td>43.1</td><td>45</td><td>45.5</td><td>39.8</td><td>45.5 </td></tr><tr><td>Rope GO</td><td>51.6</td><td>57</td><td>56</td><td>50.6</td><td>54.4</td><td>55.2</td><td>51.2</td><td>53.8</td><td>50.3</td><td>51.7 </td></tr><tr><td>Rope GQ</td><td>10.3</td><td>12.1</td><td>6.7</td><td>2.2</td><td>5.6</td><td>1.1</td><td>6.7</td><td>10.1</td><td>6.7</td><td>5.6 </td></tr><tr><td>Fluid P</td><td>10</td><td>25</td><td>54</td><td>37</td><td>51.3</td><td>50.9</td><td>54</td><td>55.3</td><td>30</td><td>50.7 </td></tr><tr><td>Fluid CO</td><td>47.3</td><td>53.3</td><td>56.8</td><td>49.1</td><td>59.5</td><td>60.4</td><td>55</td><td>55.4</td><td>56.5</td><td>57.4 </td></tr><tr><td>Fluid CQ</td><td>5.1</td><td>5.1</td><td>8.6</td><td>6</td><td>10.3</td><td>1.7</td><td>8.6</td><td>9.5</td><td>6.9</td><td>7.8 </td></tr><tr><td>Fluid GO</td><td>44.4</td><td>53.8</td><td>67.7</td><td>67.7</td><td>55.9</td><td>67.3</td><td>57.3</td><td>58.1</td><td>51.2</td><td>58.5 </td></tr><tr><td>Fluid GQ</td><td>11.3</td><td>7.5</td><td>41.3</td><td>41.3</td><td>40</td><td>41.2</td><td>22.5</td><td>27.5</td><td>17.5</td><td>25 </td></tr><tr><td>Fluid PO</td><td>52.4</td><td>50</td><td>53.8</td><td>45.5</td><td>51.7</td><td>53.2</td><td>51.4</td><td>53.2</td><td>53.5</td><td>51.9 </td></tr><tr><td>Fluid PQ</td><td>5.8</td><td>13</td><td>12.7</td><td>3.8</td><td>4.8</td><td>3.8</td><td>12.5</td><td>10.6</td><td>12.5</td><td>13.5 </td></tr><tr><td>Cloth P</td><td>42</td><td>49</td><td>59.3</td><td>54</td><td>58.7</td><td>55</td><td>46.7</td><td>47.3</td><td>59.3</td><td>59.3 </td></tr><tr><td>Cloth PO</td><td>50.1</td><td>53</td><td>68.8</td><td>61.6</td><td>63.5</td><td>68.2</td><td>67.5</td><td>68.3</td><td>57.9</td><td>60.8 </td></tr><tr><td>Cloth PQ</td><td>43</td><td>47.5</td><td>57.3</td><td>46.3</td><td>47.3</td><td>55.7</td><td>57.3</td><td>61.7</td><td>50.7</td><td>53.3 </td></tr><tr><td>Ball P</td><td>54</td><td>45</td><td>54.7</td><td>54</td><td>52.7</td><td>48</td><td>54.7</td><td>55.3</td><td>48</td><td>52.7 </td></tr><tr><td>Ball CO</td><td>60.9</td><td>66.7</td><td>66.1</td><td>63.7</td><td>67.2</td><td>65.6</td><td>64.2</td><td>66.9</td><td>66.1</td><td>66.4 </td></tr><tr><td>Ball CQ</td><td>29.6</td><td>46.9</td><td>41.8</td><td>24.6</td><td>44.3</td><td>41.8</td><td>41.8</td><td>47.5</td><td>3.3</td><td>45.9 </td></tr><tr><td>Ball GO</td><td>54.1</td><td>51.4</td><td>58.1</td><td>54.1</td><td>57.4</td><td>57.4</td><td>54.1</td><td>60.4</td><td>58.1</td><td>52.6 </td></tr><tr><td>Ball GQ</td><td>24.6</td><td>18</td><td>38.9</td><td>22.2</td><td>21.1</td><td>21.1</td><td>20</td><td>36.7</td><td>18.9</td><td>21.1 </td></tr><tr><td>Ball PO</td><td>51.7</td><td>45.4</td><td>67.4</td><td>62.9</td><td>67.4</td><td>64.4</td><td>67.4</td><td>71.2</td><td>64.4</td><td>70.5 </td></tr><tr><td>Ball PQ</td><td>25.9</td><td>17.2</td><td>46.6</td><td>6.8</td><td>17</td><td>2.3</td><td>45.5</td><td>53.4</td><td>46.6</td><td>55.7 </td></tr></table>
          <br>
        </div>  

        <div id="content9">
          <br>
          <br>
          <br>
          <h2 class="title is-3"><span style="color: rgb(192, 101, 116);"></span>Experiment Details</h2> 
          <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Logical Steps</h2>
          <h2 class="title is-5"><span style="color: rgb(192, 101, 116);"></span>(In response to Reviewer aBrg)</h2>
          
          <div class="columns is-vcentered">
            <div class="column is-6 has-text-centered">
              <img src="static/images/additional/fluid_steps.png" alt="distribution" class="interpolation-chart">
            </div>
            <div class="column is-6 has-text-centered">
              <img src="static/images/additional/rope_steps.png" alt="distribution" class="interpolation-chart">
            </div>
          </div>
          <div class="columns is-vcentered">
            <div class="column is-6 has-text-centered">
              <img src="static/images/additional/cloth_steps.png" alt="distribution" class="interpolation-chart">
            </div>
            <div class="column is-6 has-text-centered">
              <img src="static/images/additional/ball_steps.png" alt="distribution" class="interpolation-chart">
            </div>
          </div>


          <h2 class="title is-3"><span style="color: rgb(192, 101, 116);"></span>Prompting Details</h2>
          <h2 class="title is-5"><span style="color: rgb(192, 101, 116);"></span>(In response to Reviewer UVKV, xL5z, aBrg, and 7fPw)  </h2>
          <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Prompt to paraphrase questions </h2>
          
          <!-- code here -->
          <pre>
<code class="language-python"># Prompt Example: Paraphrase the question
PROMPT = ("I am looking for assistance in paraphrasing this question. "
          "My primary goal is to ensure that the essence and meaning of the question, along with the content "
          "of each option, remain unchanged. It is crucial that the sequence of the options is preserved so "
          "that the correct answer corresponds directly with the original question. Below, I will provide the "
          "question with its options. Please rephrase it as diversely as possible, maintaining strict adherence "
          "to their original meaning. Make question readable and understandable for common people as well. "
          "Please only return paraphrased question (with its paraphrased options if it has). Do not add any other text. "
          "Please keep the color name and the object name unchanged. "
          "Please do not change the word \"elastic\"/\"plastic\" or \"elasticity\"/\"plasticity\". "
          "If the object name has \"the other\" description, let this description stay unchanged. "
          "If you think the option is too hard to rephrase, you can keep it unchanged. "
          "Also, keep the option format unchanged."
          "For example, if I give you the following question:\n\n"
          "If the gray stick were removed, which stick would orange fluid pass?\nA. Pink stick\nB. Brown stick\nC. Cyan stick\n\n"
          "You may response:\n\n"
          "If the gray stick were not there, which stick would orange liquid flow through?\nA. Pink stick\nB. Cyan stick\nC. Cyan stick\n\n"
          "PLEASE STRICTLY FOLLOW above response format. Otherwise we could not use program to process your response. "
          "OK, here is the original question you will paraphrase.\n\n")
          f"{questions to paraphrase}\n\n"
          "Thank you for your assistance!")</code>
          </pre>

          <br>
          <br>
          <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Prompt of Scenario-Specific Guidelines</h2> 
          <!-- code here -->
          <pre>
<code class="language-python"># Prompt Example: Scenario-Specific Guidelines
PROMPT = ("For now I am giving you a set of frames extract from a video, with some questions related to the video. You need to answer questions in the given order. "
          "For each question please answer it in a fixed format following the comment after the question. "
          "For the overall output, you need to list the answers for all questions in the original question order, and divide them by \";\". "
          "For example, if you have two questions, and the answers are \"A B C\" and \"yes\", then you need to respond with \"A B C;yes\". "
          "Please do NOT add any other text in your response. Thank you!")
SCENARIO_INSTRUCTIONS={
    "fluid": (f"{PROMPT}"
            "Here is some additional prompts for you." 
            "Scenario Introduction: In this device, various liquids of different densities and viscosities, " 
            "each represented by distinct colors, are released from corresponding emitters situated at the "
            "uppermost part of the apparatus. Under the influence of gravity, these liquids descend and traverse "
            "a series of fixed ramps (resembling sticks). This arrangement causes alterations in their flow direction. "
            "Ultimately, the liquids are funneled into containers at the bottom. This process highlights distinctive "
            "behaviors arising from the interaction of multiple fluids, attributable to their significantly varied densities. "
            "Our research is oriented towards formulating inquiries pertaining to the physical properties of these liquids and "
            "the dynamic trajectories they exhibit."),
    "rope": (f"{PROMPT}"
            "Here is some additional prompts for you."
            "Scenario Introduction: An array of pulleys, including both movable and fixed types, along with anchor points, "
            "is arranged on a wall. Ropes are configured with their ends connected to pulleys, loads, or anchor points, and "
            "can be wound around the pulleys. These loads possess varying masses, interacting with other forces in the system, "
            "leading to the emergence of distinct motion patterns. | The primary objective of the model is to identify the tension "
            "distributions within this elementary rope system. Additionally, it is tasked with recognizing potential correlations "
            "or constraints among objects in motion, such as the coordinated movement of loads and the rotation of pulleys on a "
            "single rope. Moreover, the model is expected to infer numerical relationships between the loads' masses."),
    "cloth": (f"{PROMPT}" 
            "Here is some additional prompts for you."
            "Scenario Introduction: A small table hosts an assortment of objects, including pillars and plates of varying sizes, "
            "colors, and masses. Two square pieces of cloth, each possessing distinct stretching, bending characteristics, and "
            "frictional properties, are gripped at one edge and moved forward to cover these objects, causing possible collision "
            "events. Cloths are then promptly released. The fabric obstructs the view of the objects but also delineates their "
            "shapes through its deformable surface. Objects may topple over if they exceed a certain height or have low mass, "
            "resulting in observable changes in the fabric's dynamic 3D surface geometry.This scenario serves as a test for a "
            "model's capacity to discern the physical attributes of the fabrics and to predict the spatial behavior of the "
            "concealed objects in dynamic situations."), 
    "soft": (f"{PROMPT}" 
           "Here is some additional prompts for you."
           "Scenario Introduction: A playground contains obstacles of different color, and pose, along with pits randomly "
           "arranged within. Soft balls with varying deformation resistance or plasticity yield are launched randomly within "
           "the space, with varying initial positions. These balls undergo a sequence of dynamic movements, including bouncing "
           "and permanent deformation. Ultimately, some may collide with obstacles and fall into pits. This experimental scenario "
           "serves as a test to determine whether the model can accurately discern the elasticity and plasticity properties of the "
           "soft bodies and moreover make dynamic predictions and inferences based on these observations.")
}</code>
          </pre>


          <br>
          <br>
          <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Prompt of In-Context Examples</h2> 
          <!-- code here -->
          <pre>
<code class="language-python"># Prompt Example: In-Context Examples
SCENARIO_EXAMPARS = {
    "fluid": # final 17 as the example
        [
            "Here are some additional examples for you to get the feeling of how to solve the problem.",
            [data_dirs["fluid"]["videos"] + "/17/frames/output_Full_ori/frame_00247.png"],
            "Above is the last frame of example video. The example questions are: \
                (1)\"Is the density of the blue fluid greater than that of the green fluid?\" \
                (2)\"Will the yellow fluid which is emitting at the last frame finally enter the white container?\" \
                    The correct answers for these questions are (1)\"no\" (2)\"no\". \
                    \n\nOK. Since you have got some examples for reference. The following questions are for you!"
        ],
    "rope": # final2 27 as the example
        [
            "Here are some additional examples for you to get the feeling of how to solve the problem.",
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00031.png"],
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00062.png"],
            "Above are some sampled sequential frames of example video. The example questions are: \
                (1)\"Is the mass of the cyan sphere greater than half that of the gray sphere?\" \
                (2)\"If the cyan sphere were far much heavier, which direction would the brown pulley rotate? A. Anti-clockwise B. Clockwise C. Not affected\" \
                    The correct answers for these questions are (1)\"no\" (2)\"B\". \
                    \n\nOK. Since you have got some examples for reference. The following questions are for you!"
        ],
    "cloth": # final2 32 as the example
        [
            "Here are some additional examples for you to get the feeling of how to solve the problem.",
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00080.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00095.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00142.png"],
            "Above are some selected sequential frames of example video. The example questions are: \
                (1)\"Is the left cloth much easier to bend or have wrinkles than the other?\" \
                (2)\"Is the elasticity of the right cloth much greater than that of the other?\" \
                (3)\"Does the orange pillar collide with the gray plate?\" \
                (4)\"Which phrase below can best describe the final pose of the cyan plate? A. Standing upright B. Leaning C. Lying horizontally\" \
                    The correct answers for these questions are (1)\"yes\" (2)\"no\" (3)\"no\" (4)\"C\". \
                    \n\nOK. Since you have got some examples for reference. The following questions are for you!"
        ],
    "soft": # final 9 as the example
        [
            "Here are some additional examples for you to get the feeling of how to solve the problem.",
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00020.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00025.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00035.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00087.png"],
            "Above are some selected sequential frames of example video. The example questions are: \
                (1)\"Is the elasticity of the orange ball much greater than the blue ball?\" \
                (2)\"Is the plasticity of the cyan ball much greater than the orange ball?\" \
                (3)\"Which pit will the cyan ball finally drop into? A. The left pit B. The right pit C. It will not drop into any pits\" \
                    The correct answers for these questions are (1)\"yes\" (2)\"yes\" (3)\"A\". \
                    \n\nOK. Since you have got some examples for reference. The following questions are for you!"
        ]
}</code>
          </pre>


          <br>
          <br>
          <h2 class="title is-4"><span style="color: rgb(192, 101, 116);"></span>Prompt of Human Explained Examples</h2> 
          <!-- code here -->
          <pre>
<code class="language-python"># Prompt Example: Human Explained Examples
  SCENARIO_HUMAN_EXPL = {
    "fluid": # final 17 as the example
        [
            "Here are some additional detailed guidance/tutorial for you to get the feeling of how to solve the problems.",
            [data_dirs["fluid"]["videos"] + "/17/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["fluid"]["videos"] + "/17/frames/output_Full_ori/frame_00247.png"],
            "Above 2 images are the first and the last frames from an example video. "
            "In the next question-answering part we will give you some sparsely sampled frames in another similar video. In both example and target videos, "
            "users will firstly see colored fluids emitted from the top emitters which look like colored cubes. Then the fluids will drop upon and flow down "
            "along several colored ramps which look like sticks, and finally the fluids will enter one or several colored containers at the bottom, which constructed by several long sticks. "
            "Make sure you can detect these key objects. The fluids have different colors, which represent different densities. The fluids will collide with each other and the ramps during the process. "
            "Finally in the container they will stratify into obvious layers. Note that the lighter fluid will float on the heavier fluid! This is very important when you choose answers about density. "
            "Also note that the process is governed by the gravity. The questions will be about the density, the flow direction, the collision, and the final container of the fluids. "
            "At the end of the video, there might be some fluids starting emitting but not yet entering any containers. You need to predict which container and stick they will contact with. "
            "\nTake the above 2 example images as example, in the last frame, you can see blue fluid is floating upon the green fluid in the white container, while the yellow fluid is floating upon "
            "the green fluid in the gray container. So you can answer the density question based on this observation, which means for most of the time you can only analyze the last frame to determine the density relations. "
            "\n Also, in the last frame, you may notice the green fluid is emitting on left top side. You can predict that, under the gravity, it will drop onto the orange stick, flow along the orange stick, and then drop onto the green stick, "
            "then flow along the green stick. Then it will finally drop into the white container. Through this reasoning logic chain, you can solve some problems like the following examples. "
            "\nThe example questions are: "
            "(1)\"Is the density of the blue fluid greater than that of the green fluid?\" "
            "(2)\"Will the green fluid which is emitting at the last frame finally enter the gray container?\" "
            "The correct answers for these questions are (1)\"no\" (2)\"no\". "
            "\n\nOK. Since you have got some examples for reference. The following questions are for you! Forget the above images now and just focus on the following images."
        ],
    "rope": # final2 27 as the example
        [
            "Here are some additional detailed guidance/tutorial for you to get the feeling of how to solve the problems.",
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00031.png"],
            [data_dirs["rope"]["videos"] + "/27/frames/output_Full_ori/frame_00062.png"],
            "Above 3 images are the first, the 31st, and the 62th frames from an example video. "
            "In the next question-answering part we will give you some sparsely sampled frames in another similar video. In both example and target videos, "
            "users will firstly see some pulleys, some fixed on the wall, only able to rotate around itself, some movable and rotatable. Fixed pulleys are "
            "fixed by fixed cylinders at their center. You may also observe colored spheres or cubes connected by ropes. The ropes are wound around pulleys. "
            "The spheres or cubes have different colors, which represent different masses. These objects are statically released at the beginning of the video. "
            "Due to gravity and the tension of the rope, the pulley-rope system may show various dynamic behaviors. And you can infer some properties in this visual dynamics. "
            "\nTake the above 3 example images as example, you can see, in the sequential dynamics, the cyan sphere was lifted by the rope despite of gravity, and the gray sphere dropped. "
            "the gray sphere is connected to the brown movable pulley by a short gray rope. The cyan sphere is connected to the red rope which is wound around the orange pulley, brown pulley, and the gray pulley. "
            "The other end of the red rope is connected to a white fixed point, which looks like a rectangular cuboid. So you can infer that the tension in the red rope is probably half of that in the gray short rope, "
            "which approximately equals to the gravity of the gray sphere. We can know that the tension in the red rope approximately equals to the gravity of the cyan sphere. Thus, when you see the cyan sphere rises, "
            "you can infer that the mass of the cyan sphere is less than half that of the gray sphere. You may continue your reasoning process. If we make the cyan sphere much heavier, it will drag the red rope down, "
            "causing the brown pulley lifted due to the existance of the orange pulley and the rope length constraint. So the left end of the brown pulley will be lifted while the right side is static because of "
            "the other side of the red rope is connected to a fixed point. Thus we can draw a conclusion that the brown movable pulley would rotate clockwise if the cyan sphere were much heavier. "
            "\nThrough this reasoning logic chain, you can solve some problems like the following examples. "
            "\nThe example questions are: "
            "(1)\"Is the mass of the cyan sphere greater than half that of the gray sphere?\" "
            "(2)\"If the cyan sphere were far much heavier, which direction would the brown pulley rotate? A. Anti-clockwise B. Clockwise C. Not affected\" "
            "The correct answers for these questions are (1)\"no\" (2)\"B\". "
            "\n\nOK. Since you have got some examples for reference. The following questions are for you! Forget the above images now and just focus on the following images."
        ],
    "cloth": # final2 32 as the example
        [
            "Here are some additional detailed guidance/tutorial for you to get the feeling of how to solve the problems.",
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00080.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00095.png"],
            [data_dirs["cloth"]["videos"] + "/32/frames/output_Full_ori/frame_00142.png"],
            "Above 4 images are the first, the 80th, the 95th, and the 142th frames from an example video. "
            "In the next question-answering part we will give you some sparsely sampled frames in another similar video. In both example and target videos, "
            "users will firstly see two pairs of objects respectively placed on the left and right sides of a table. A pair of objects consists of a colored pillar at the front and a colored plate behind. "
            "Individual objects have different masses, some really heavy, some really light. Two square pieces of cloth, each possessing distinct stretching, bending characteristics, and frictional properties, "
            "are gripped at one edge and moved forward to cover these objects, causing possible collision events. Users can observe the surface deformation of the cloths, which may help users to infer the falling "
            "or collision event happening behind the cloth and can indicate the final pose of the objects. "
            "\nTake the above 4 example images as example, you can see in the first frame, there are yellow pillar left, cyan plate left, orange pillar right, and gray plate right. "
            "From the 80th and 95th frame, users may infer from the contour of the cloth that the yellow pillar might have fallen down, and the cyan plate might have fallen down as well (due to the collision between pillar and plate). "
            "As for the right pair of objects, the orange pillar seems not to have moved. Maybe it is because the orange pillar is too heavy to push down. From the 142th frame, user may also infer that the gray plate is still standing as well."
            "And the cyan plate and the yellow pillar are finally both lying down horizonally on the table, covered by the cloth. So you can answer the questions about the final pose of the objects based on these observations. "
            "As for the bending compliance question, you can infer from the wrinkles on each cloth. The left cloth has more fine-grained wrinkles, shown especially on its edge or contour. In contrast, the right cloth's edges are more smooth curves. "
            "So you can answer the bending compliance question based on this observation. Also, you can infer the elasticity of the cloth from the texture distortion of the cloth. The left cloth has more "
            "distortion compared with the original texture when it is dragged, stretched, and collided into. While the right cloth's texture is relatively more stable when it is manipulated, indicating that it is more stiff in elasticity or stretchiness. "
            "\nThrough this reasoning logic chain, you can solve some problems like the following examples. "
            "\nThe example questions are: "
            "(1)\"Is the left cloth much easier to bend or have wrinkles than the other?\" "
            "(2)\"Is the elasticity of the right cloth much greater than that of the other?\" "
            "(3)\"Does the orange pillar collide with the gray plate?\" "
            "(4)\"Which phrase below can best describe the final pose of the cyan plate? A. Standing upright B. Leaning C. Lying horizontally\" "
            "The correct answers for these questions are (1)\"yes\" (2)\"no\" (3)\"no\" (4)\"C\". "
            "\n\nOK. Since you have got some examples for reference. The following questions are for you! Forget the above images now and just focus on the following images."
        ],
    "soft": # final 9 as the example
        [
            "Here are some additional detailed guidance/tutorial for you to get the feeling of how to solve the problems.",
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00000.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00020.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00025.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00035.png"],
            [data_dirs["soft"]["videos"] + "/9/frames/output_Full_ori/frame_00087.png"],
            "Above 5 images are the first, the 20th, the 25th, the 35th, and the 87th frames from an example video."
            "In the next question-answering part we will give you some sparsely sampled frames in another similar video. In both example and target videos, "
            "users will firstly see three colored balls free falling from a high position, then dropping onto the colored ramps, colliding with ramps, and them keep moving. "
            "The balls have different colors, which represent different elasticity and/or plasticity. Among the three balls, one of them is obviously plastic and easy to permanently deform, "
            "one is obviously elastic, non-plastic, and easy to deform but will quickly recover to the original shape. The last ball is non-elastic and non-plastic, which seems to be an underformable rigid ball. "
            "You have to distinguish which one is plastic, which one is elastic, and which one is rigid. The balls will collide with obstacles and fall into pits. There are two pits on the playground, on the left and right, "
            "as you can see in the example images. You need to predict which pit the ball will finally drop into if it haven't. "
            "\nTake the above 5 example images as example, you can see in the first frame, 3 balls are statically released at high positions by invisible hands. "
            "In the 20th frame, the orange ball is colliding with the cyan ramp, causing significant deformation, while the other two balls are still falling. "
            "In the 25th frame, the orange ball finishes colliding and bounces up, recovering its shape back to original, indicating it is very elastic, while the cyan ball is colliding with the green ramp, causing significant deformation. "
            "The blue ball is colliding with the blue ramp, yet no significant deformation shown. "
            "In the 35th frame, the cyan ball finishes colliding and bounces up, but unable to recover its shape back to original, indicating it is permanently deformed and very plastic. "
            "The blue ball finishes collision and bounces forward. Judging from its behavior and shape change, blue ball seems like a rigid ball, without elasticity and plasticity. "
            "In the 87th frame, the orange ball and the blue ball are entering the left and right pits respectively. And the cyan ball is still slowly sliding at the left shore of the left pit, moving towards the left pit. "
            "So you can image it will next enter the left pit. Then based on the above observation, analysis, and inference, you can simply answer relative questions. "
            "\nThrough this reasoning logic chain, you can solve some problems like the following examples. "
            "\nThe example questions are: "
            "(1)\"Is the elasticity of the orange ball much greater than the blue ball?\" "
            "(2)\"Is the plasticity of the cyan ball much greater than the orange ball?\" "
            "(3)\"Which pit will the cyan ball finally drop into? A. The left pit B. The right pit C. It will not drop into any pits\" "
            "The correct answers for these questions are (1)\"yes\" (2)\"yes\" (3)\"A\". "            
            "\n\nOK. Since you have got some examples for reference. The following questions are for you! Forget the above images now and just focus on the following images."
        ]
}</code>
          </pre>


        </div>
      <!-- </div> -->
      
    <!-- </div> -->
    
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div id="content9">
          <br/>
          <br/>
          <br/>
          <h2 class="title is-2">Dataset Details</h2>
          <div class="columns is-vcentered">
            <div class="column is-12 has-text-centered">
              <div class="item item-fullbody">
                <video poster="static/videos/teasers/sensor.jpg" id="fullbody"  controls muted loop playsinline height="100%">
                  <source src="./static/videos/teasers/sensors.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          <h2 class="content has-text-justified">
            Sensor data outputs are multimodal, depicting the 4D states of objects across various levels,
            ranging from object-level, point-level to event-level.
          </h2>
        </div>
      </div>
    </div> -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/---.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/---" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- <p>
            This paper is <a
            href=""></a>.
          </p> -->
          <p>
            Licensed under <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. Template borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

  <!-- JavaScript Bundle with Popper -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
  <script src="main.js"></script>
  <script>
    $(document).ready(function() {
      $("a[href^='#']").on('click', function(event) {
        var target = $(this.getAttribute('href'));
        if (target.length) {
          event.preventDefault();
          $('html, body').stop().animate({
            scrollTop: target.offset().top
          }, 400);
        }
      });
    });
    </script>
  <a href="#" id="back-to-top" title="Back to top"><i class="fas fa-arrow-up"></i></a>
</body>
</html>
